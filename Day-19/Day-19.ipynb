{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 19 Exercise\n",
    "### Exercise Level 1\n",
    "### Number 1a: Function to count number of lines and words in Obama speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lines_words(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        line_count = len(lines)\n",
    "        words = ' '.join(lines).split()\n",
    "        word_count = len(words)\n",
    "    return line_count, word_count\n",
    "\n",
    "obama_lines, obama_words = count_lines_words(file_path= r'C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\obama_speech.txt')\n",
    "print(f'The number of lines in Obama speech are: {obama_lines}')\n",
    "print(f'The number of words in the Obama speech are: {obama_words}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number 1b: Function to count number of lines and words in Michelle speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "michelle_lines, michelle_words = count_lines_words(file_path= r'C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\michelle_obama_speech.txt')\n",
    "print(f'The number of lines in Michelle Obama speech are: {michelle_lines}')\n",
    "print(f'The number of words in Micheele Obama speech are: {michelle_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number 1c: Function to count number of lines and words in Donald speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donald_lines, donald_words = count_lines_words(file_path= r'C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\donald_speech.txt')\n",
    "print(f'The number of lines in Donald speech are: {donald_lines}')\n",
    "print(f'The number of words in Donald speech are: {donald_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number 1d: Function to count number of lines and words in Melina Trump speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melina_lines, melina_words = count_lines_words(file_path= r'C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\melina_trump_speech.txt')\n",
    "print(f'The number of lines in Melina speech are: {melina_lines}')\n",
    "print(f'The number of words in Melina speech are: {melina_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number 2: Finding ten most spoken countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def most_spoken_languages(filename, limit):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        languages = [country['languages'].split(', ') for country in data]\n",
    "        languages_flat = [language for sublist in languages for language in sublist]\n",
    "        language_count = Counter(languages_flat)\n",
    "        return language_count.most_common(limit)\n",
    "\n",
    "filename = r\"C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\countries_data.json\"\n",
    "\n",
    "print(most_spoken_languages(filename, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number 3: Function thst creates a list of 10 most populated countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_populated_countries(filename, limit):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        sorted_countries = sorted(data, key=lambda x: x['population'], reverse=True)\n",
    "        return [{'country': country['name'], 'population': country['population']} for country in sorted_countries[:limit]]\n",
    "        \n",
    "    \n",
    "#file_path = filename\n",
    "print(most_populated_countries(filename, 10))\n",
    "print(most_populated_countries(filename, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Level 2\n",
    "### Number 1: Extracting all incoming email addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_emails(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "    return emails\n",
    "\n",
    "file_path = r'C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\email_exchanges_big.txt'\n",
    "\n",
    "emails_list = extract_emails(file_path)\n",
    "print(emails_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Most common words in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_common_words(file_path, limit):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read().lower()\n",
    "        words = re.findall(r'\\b\\w+\\b', text)\n",
    "        word_count = Counter(words)\n",
    "        return word_count.most_common(limit)\n",
    "\n",
    "\n",
    "print(find_most_common_words(file_path, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number 3: Ten most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\Day-19\\Day-19.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ArewaDS/ArewaDS-30days-of-Python/Day-19/Day-19.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m word_count\u001b[39m.\u001b[39mmost_common(limit)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ArewaDS/ArewaDS-30days-of-Python/Day-19/Day-19.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDesktop\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mArewaDS\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mArewaDS-30days-of-Python\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mobama_speech.txt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ArewaDS/ArewaDS-30days-of-Python/Day-19/Day-19.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m obama_frequent \u001b[39m=\u001b[39m find_most_frequent_words(file_path, \u001b[39m10\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ArewaDS/ArewaDS-30days-of-Python/Day-19/Day-19.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(obama_frequent)\n",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\Day-19\\Day-19.ipynb Cell 18\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ArewaDS/ArewaDS-30days-of-Python/Day-19/Day-19.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m words \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb[A-Za-z0-9._\u001b[39m\u001b[39m%\u001b[39m\u001b[39m+-]+@[A-Za-z0-9.-]+\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.[A-Z|a-z]\u001b[39m\u001b[39m{\u001b[39m\u001b[39m2,}\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ArewaDS/ArewaDS-30days-of-Python/Day-19/Day-19.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m words \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39msplit\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ArewaDS/ArewaDS-30days-of-Python/Day-19/Day-19.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m word_count \u001b[39m=\u001b[39m Counter(words)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ArewaDS/ArewaDS-30days-of-Python/Day-19/Day-19.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m word_count\u001b[39m.\u001b[39mmost_common(limit)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311-32\\Lib\\collections\\__init__.py:599\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \u001b[39mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[39mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m \n\u001b[0;32m    597\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m--> 599\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(iterable, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311-32\\Lib\\collections\\__init__.py:690\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    688\u001b[0m             \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mupdate(iterable)\n\u001b[0;32m    689\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 690\u001b[0m         _count_elements(\u001b[39mself\u001b[39m, iterable)\n\u001b[0;32m    691\u001b[0m \u001b[39mif\u001b[39;00m kwds:\n\u001b[0;32m    692\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(kwds)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not iterable"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_most_frequent_words(file_path, limit=10):\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read().lower()\n",
    "        words = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "        words = text.split\n",
    "        word_count = Counter(words)\n",
    "       \n",
    "        return word_count.most_common(limit)\n",
    "\n",
    "    \n",
    "\n",
    "file_path = r\"C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\obama_speech.txt\"\n",
    "obama_frequent = find_most_frequent_words(file_path, 10)\n",
    "\n",
    "print(obama_frequent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Similrities between two texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import difflib\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return ' '.join(cleaned_text.split()).lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    with open(r'C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\stop_words.py', 'r') as file:\n",
    "        stop_words = file.read().split(',')\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def check_text_similarity(text1, text2):\n",
    "    cleaned_text1 = remove_stop_words(clean_text(text1))\n",
    "    cleaned_text2 = remove_stop_words(clean_text(text2))\n",
    "    similarity_percentage = difflib.SequenceMatcher(None, cleaned_text1, cleaned_text2).ratio() * 100\n",
    "    return similarity_percentage\n",
    "\n",
    "text1 = r\"C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\michelle_obama_speech.txt\" \n",
    "\n",
    "text2 = r\"C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\melina_trump_speech.txt\" \n",
    "similarity = check_text_similarity(text1, text2)\n",
    "\n",
    "print(f' Similrities between two texts is {similarity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Ten most repeated words in romeo and juliet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_repeated_words(file_path, limit):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read().lower()\n",
    "        words = re.findall(r'\\b\\w+\\b', text)\n",
    "        word_count = Counter(words)\n",
    "        return word_count.most_common(limit)\n",
    "\n",
    "repeated_words = r'C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\romeo_and_juliet.txt'\n",
    "print(f'{most_repeated_words(repeated_words, 10)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Reading Hacker news csv\n",
    "### 6a: Number of lines containing python or Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def count_specific_words(csv_path, *words):\n",
    "    with open(csv_path, newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        count = 0\n",
    "        for row in reader:\n",
    "            line = ' '.join(row).lower()\n",
    "            if all(word.lower() in line for word in words):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# Usage example:\n",
    "python_count = count_specific_words(r'C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\hacker_news.csv', 'python')\n",
    "\n",
    "print(f'Number of lines containing Java not JavaScript is: {python_count} lines')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b: Number of lines containing JavaScript, javascript or Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript_count = count_specific_words(r'C:\\Users\\user\\Desktop\\ArewaDS\\ArewaDS-30days-of-Python\\data\\hacker_news.csv', 'javascript', 'java')\n",
    "\n",
    "print(f'Number of lines containing JavaScript is: {javascript_count} lines')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c: Number of lines containing Java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
